{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Final IDL_Assignment4.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "QxFeEh8TS4Hu",
        "au-ejyuTZDKC",
        "0h2mY-Mfdqmo",
        "q9R1Qj9zZLmF"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tq2QDgB_-7fZ",
        "colab_type": "text"
      },
      "source": [
        "GROUP MEMBERS :\n",
        "1.  Aniruddh Shukla \n",
        "2. Gaurav Singhal \n",
        "3. Himanshi Bajaj \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QxFeEh8TS4Hu",
        "colab_type": "text"
      },
      "source": [
        "# with tf.function "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QLElAjwAYZdL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import traceback\n",
        "import contextlib\n",
        "import time\n",
        "import tensorboard\n",
        "from datetime import datetime\n",
        "from tensorflow.keras import datasets,layers, models\n",
        "from keras import regularizers\n",
        "tf.config.experimental_run_functions_eagerly(True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7s-eSwBsIkHj",
        "colab_type": "code",
        "outputId": "1cfcb224-d744-4e76-e232-3a01b54900ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sUGwGKScZ20f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.chdir(\"/content/drive/My Drive/Colab Notebooks\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UvraEFwbBTCx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
        "\n",
        "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
        "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
        "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
        "data = tf.data.Dataset.from_tensor_slices(\n",
        "    (train_images.astype(np.float32) / 255.0, train_labels.astype(np.int32)))\n",
        "data = data.batch(128)\n",
        "\n",
        "# note: we batch the test data, but do not shuffle/repeat\n",
        "test_data = tf.data.Dataset.from_tensor_slices(\n",
        "    (test_images.astype(np.float32) / 255.0, test_labels.astype(np.int32))).batch(128)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bTE189lzBTSY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epochs = 10\n",
        "n_h = 256\n",
        "model = models.Sequential([\n",
        "              layers.Conv2D(32, 3, padding= 'same' , activation= 'relu', input_shape = (28, 28, 1) ,  kernel_initializer= 'he_uniform'),\n",
        "              layers.BatchNormalization(),\n",
        "              layers.Conv2D(32, 3 , padding= 'same', activation = 'relu',  kernel_initializer= 'he_uniform'),\n",
        "              layers.BatchNormalization(),\n",
        "              layers.MaxPooling2D(),\n",
        "              layers.Dropout((0.3)),\n",
        "\n",
        "              layers.Conv2D(64, 3 , padding= 'same', activation = 'relu' ,  kernel_initializer= 'he_uniform'),\n",
        "              layers.BatchNormalization(),\n",
        "              layers.Conv2D(64, 3 , padding= 'same', activation = 'relu' ,  kernel_initializer= 'he_uniform'),\n",
        "              layers.BatchNormalization(),\n",
        "              layers.MaxPooling2D(),\n",
        "              layers.Dropout((0.4)),\n",
        "\n",
        "              layers.Conv2D(128, 3, padding= 'same', activation= 'relu' ,  kernel_initializer= 'he_uniform'),\n",
        "              layers.BatchNormalization(),\n",
        "              layers.Conv2D(128, 3, padding= 'same', activation= 'relu' ,  kernel_initializer= 'he_uniform'),\n",
        "              layers.BatchNormalization(),\n",
        "              layers.MaxPooling2D(),\n",
        "              layers.Dropout((0.5)),\n",
        "\n",
        "              layers.Flatten(),\n",
        "              layers.Dense(n_h, activation='relu' , kernel_initializer= 'he_uniform'),\n",
        "              layers.BatchNormalization(),\n",
        "              layers.Dense(n_h//2, activation='relu' , kernel_initializer= 'he_uniform'),\n",
        "              layers.Dense(10)\n",
        "              ])\n",
        "\n",
        "#model.build((None, 784))  # optional -- note None for the batch axis!!\n",
        "\n",
        "opt = tf.optimizers.Adam(learning_rate= 5 * 1e-3)\n",
        "# from_logits = True!! #neverforget\n",
        "loss_fn = tf.losses.SparseCategoricalCrossentropy(from_logits=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G3gXoZEBBTgM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@tf.function\n",
        "def gradient(img_batch, lbl_batch):\n",
        "  with tf.GradientTape() as tape:\n",
        "      logits = model(img_batch, training=True)\n",
        "        # loss format is generally: first argument targets, second argument outputs\n",
        "      xent = loss_fn(lbl_batch, logits)\n",
        "\n",
        "  varis = model.trainable_variables\n",
        "  grads = tape.gradient(xent, varis)\n",
        "  opt.apply_gradients(zip(grads, varis))\n",
        "  return logits,xent"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1K6gaiX0BTyQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 731
        },
        "outputId": "27c56d5b-9343-49bd-b04f-29921c09d89b"
      },
      "source": [
        "train_acc_metric = tf.keras.metrics.SparseCategoricalAccuracy()\n",
        "total_start = time.time()\n",
        "for epoch in range(epochs):\n",
        "  start = time.time()\n",
        "  tf.print(\"epoch number :\", epoch)\n",
        "  for step , (img_batch, lbl_batch) in enumerate(data):\n",
        "    logits,xent = gradient(img_batch, lbl_batch)\n",
        "    train_acc_metric(lbl_batch, logits)\n",
        "    \n",
        "  tf.print(\"Loss: {} Accuracy: {}\".format(xent, train_acc_metric.result()))\n",
        "  train_acc_metric.reset_states()\n",
        "  stop = time.time()\n",
        "  tf.print(\"took {} seconds\\n\".format(stop-start))\n",
        "total_stop = time.time()\n",
        "tf.print(\"took {} seconds\\n\".format(total_stop-total_start))"
      ],
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch number : 0\n",
            "Loss: 0.3688471019268036 Accuracy: 0.8211833238601685\n",
            "took 29.49846863746643 seconds\n",
            "\n",
            "epoch number : 1\n",
            "Loss: 0.33544862270355225 Accuracy: 0.8852999806404114\n",
            "took 29.558159828186035 seconds\n",
            "\n",
            "epoch number : 2\n",
            "Loss: 0.22858427464962006 Accuracy: 0.8987333178520203\n",
            "took 29.38642954826355 seconds\n",
            "\n",
            "epoch number : 3\n",
            "Loss: 0.2160230129957199 Accuracy: 0.9066333174705505\n",
            "took 29.398242712020874 seconds\n",
            "\n",
            "epoch number : 4\n",
            "Loss: 0.26181963086128235 Accuracy: 0.9121833443641663\n",
            "took 29.44110679626465 seconds\n",
            "\n",
            "epoch number : 5\n",
            "Loss: 0.22560228407382965 Accuracy: 0.9173666834831238\n",
            "took 29.55054473876953 seconds\n",
            "\n",
            "epoch number : 6\n",
            "Loss: 0.22394298017024994 Accuracy: 0.9201333522796631\n",
            "took 29.438296794891357 seconds\n",
            "\n",
            "epoch number : 7\n",
            "Loss: 0.1731649786233902 Accuracy: 0.9253000020980835\n",
            "took 29.403552055358887 seconds\n",
            "\n",
            "epoch number : 8\n",
            "Loss: 0.15514110028743744 Accuracy: 0.927133321762085\n",
            "took 29.555477619171143 seconds\n",
            "\n",
            "epoch number : 9\n",
            "Loss: 0.23071520030498505 Accuracy: 0.9298499822616577\n",
            "took 29.470384120941162 seconds\n",
            "\n",
            "took 294.7211720943451 seconds\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xwc4b3mlBpa2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5bca03fe-a886-4a9a-c2fb-5bc6afe2967a"
      },
      "source": [
        "test_acc_metric = tf.keras.metrics.SparseCategoricalAccuracy()\n",
        "for img_batch, lbl_batch in test_data:\n",
        "  test_acc_metric(lbl_batch, model(img_batch))\n",
        "tf.print(\"Test acc: {}\".format(test_acc_metric.result()))"
      ],
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test acc: 0.9161999821662903\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qlo-r4SwTYx1",
        "colab_type": "code",
        "outputId": "13a3c6bb-47ea-4bb8-f68a-9dfaf7922c1d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360
        }
      },
      "source": [
        "print(tf.autograph.to_code(gradient.python_function))"
      ],
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "def tf__gradient(img_batch, lbl_batch):\n",
            "    do_return = False\n",
            "    retval_ = ag__.UndefinedReturnValue()\n",
            "    with ag__.FunctionScope('gradient', 'fscope', ag__.ConversionOptions(recursive=True, user_requested=True, optional_features=(), internal_convert_user_code=True)) as fscope:\n",
            "        with tf.GradientTape() as tape:\n",
            "            logits = ag__.converted_call(model, (img_batch,), dict(training=True), fscope)\n",
            "            xent = ag__.converted_call(loss_fn, (lbl_batch, logits), None, fscope)\n",
            "        varis = model.trainable_variables\n",
            "        grads = ag__.converted_call(tape.gradient, (xent, varis), None, fscope)\n",
            "        ag__.converted_call(opt.apply_gradients, (ag__.converted_call(zip, (grads, varis), None, fscope),), None, fscope)\n",
            "        try:\n",
            "            do_return = True\n",
            "            retval_ = fscope.mark_return_value((logits, xent))\n",
            "        except:\n",
            "            do_return = False\n",
            "            raise\n",
            "    (do_return,)\n",
            "    return ag__.retval(retval_)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "au-ejyuTZDKC",
        "colab_type": "text"
      },
      "source": [
        "# Without tf.function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "egDWcZ_GGdMv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
        "\n",
        "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
        "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
        "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
        "data = tf.data.Dataset.from_tensor_slices(\n",
        "    (train_images.astype(np.float32) / 255.0, train_labels.astype(np.int32)))\n",
        "data = data.batch(128)\n",
        "\n",
        "# note: we batch the test data, but do not shuffle/repeat\n",
        "test_data = tf.data.Dataset.from_tensor_slices(\n",
        "    (test_images.astype(np.float32) / 255.0, test_labels.astype(np.int32))).batch(128)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "glIDvREUBzV2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epochs = 10\n",
        "n_h = 256\n",
        "model = models.Sequential([\n",
        "              layers.Conv2D(32, 3, padding= 'same' , activation= 'relu', input_shape = (28, 28, 1) ,  kernel_initializer= 'he_uniform'),\n",
        "              layers.BatchNormalization(),\n",
        "              layers.Conv2D(32, 3 , padding= 'same', activation = 'relu',  kernel_initializer= 'he_uniform'),\n",
        "              layers.BatchNormalization(),\n",
        "              layers.MaxPooling2D(),\n",
        "              layers.Dropout((0.3)),\n",
        "\n",
        "              layers.Conv2D(64, 3 , padding= 'same', activation = 'relu' ,  kernel_initializer= 'he_uniform'),\n",
        "              layers.BatchNormalization(),\n",
        "              layers.Conv2D(64, 3 , padding= 'same', activation = 'relu' ,  kernel_initializer= 'he_uniform'),\n",
        "              layers.BatchNormalization(),\n",
        "              layers.MaxPooling2D(),\n",
        "              layers.Dropout((0.4)),\n",
        "\n",
        "              layers.Conv2D(128, 3, padding= 'same', activation= 'relu' ,  kernel_initializer= 'he_uniform'),\n",
        "              layers.BatchNormalization(),\n",
        "              layers.Conv2D(128, 3, padding= 'same', activation= 'relu' ,  kernel_initializer= 'he_uniform'),\n",
        "              layers.BatchNormalization(),\n",
        "              layers.MaxPooling2D(),\n",
        "              layers.Dropout((0.5)),\n",
        "\n",
        "              layers.Flatten(),\n",
        "              layers.Dense(n_h, activation='relu' , kernel_initializer= 'he_uniform'),\n",
        "              layers.BatchNormalization(),\n",
        "              layers.Dense(n_h//2, activation='relu' , kernel_initializer= 'he_uniform'),\n",
        "              layers.Dense(10)\n",
        "              ])\n",
        "\n",
        "#model.build((None, 784))  # optional -- note None for the batch axis!!\n",
        "\n",
        "opt = tf.optimizers.Adam(learning_rate= 5 * 1e-3)\n",
        "# from_logits = True!! #neverforget\n",
        "loss_fn = tf.losses.SparseCategoricalCrossentropy(from_logits=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9j9vaSpGBzje",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def gradient(img_batch, lbl_batch):\n",
        "  with tf.GradientTape() as tape:\n",
        "      logits = model(img_batch, training=True)\n",
        "        # loss format is generally: first argument targets, second argument outputs\n",
        "      xent = loss_fn(lbl_batch, logits)\n",
        "\n",
        "  varis = model.trainable_variables\n",
        "  grads = tape.gradient(xent, varis)\n",
        "  opt.apply_gradients(zip(grads, varis))\n",
        "  return logits,xent"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZzV0kgQJBzxH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 731
        },
        "outputId": "fdc9898d-eb7b-4aab-a69e-3769a191ea0a"
      },
      "source": [
        "train_acc_metric = tf.keras.metrics.SparseCategoricalAccuracy()\n",
        "total_start = time.time()\n",
        "for epoch in range(epochs):\n",
        "  start = time.time()\n",
        "  print(\"epoch number :\", epoch)\n",
        "  for step , (img_batch, lbl_batch) in enumerate(data):\n",
        "    logits,xent = gradient(img_batch, lbl_batch)\n",
        "    train_acc_metric(lbl_batch, logits)\n",
        "    \n",
        "  print(\"Loss: {} Accuracy: {}\".format(xent, train_acc_metric.result()))\n",
        "  train_acc_metric.reset_states()\n",
        "  stop = time.time()\n",
        "  print(\"took {} seconds\\n\".format(stop-start))\n",
        "total_stop = time.time()\n",
        "print(\"took {} seconds\\n\".format(total_stop-total_start))"
      ],
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch number : 0\n",
            "Loss: 0.3062203824520111 Accuracy: 0.8267999887466431\n",
            "took 29.65989637374878 seconds\n",
            "\n",
            "epoch number : 1\n",
            "Loss: 0.3652175962924957 Accuracy: 0.8876333236694336\n",
            "took 29.68651247024536 seconds\n",
            "\n",
            "epoch number : 2\n",
            "Loss: 0.1978093385696411 Accuracy: 0.8990333080291748\n",
            "took 29.489609479904175 seconds\n",
            "\n",
            "epoch number : 3\n",
            "Loss: 0.22875304520130157 Accuracy: 0.9081666469573975\n",
            "took 29.466538429260254 seconds\n",
            "\n",
            "epoch number : 4\n",
            "Loss: 0.1916522979736328 Accuracy: 0.9141499996185303\n",
            "took 29.505297899246216 seconds\n",
            "\n",
            "epoch number : 5\n",
            "Loss: 0.18503062427043915 Accuracy: 0.9180999994277954\n",
            "took 29.45931911468506 seconds\n",
            "\n",
            "epoch number : 6\n",
            "Loss: 0.16792505979537964 Accuracy: 0.9205333590507507\n",
            "took 29.673495054244995 seconds\n",
            "\n",
            "epoch number : 7\n",
            "Loss: 0.18069429695606232 Accuracy: 0.9257500171661377\n",
            "took 29.50028133392334 seconds\n",
            "\n",
            "epoch number : 8\n",
            "Loss: 0.15301354229450226 Accuracy: 0.9273999929428101\n",
            "took 29.49857258796692 seconds\n",
            "\n",
            "epoch number : 9\n",
            "Loss: 0.1370074301958084 Accuracy: 0.928683340549469\n",
            "took 29.446802377700806 seconds\n",
            "\n",
            "took 295.3883566856384 seconds\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dm8XAic0Bz_P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3dd827d9-b56a-4c55-8a4a-79a550e91aec"
      },
      "source": [
        "test_acc_metric = tf.keras.metrics.SparseCategoricalAccuracy()\n",
        "for img_batch, lbl_batch in test_data:\n",
        "  test_acc_metric(lbl_batch, model(img_batch))\n",
        "print(\"Test acc: {}\".format(test_acc_metric.result()))"
      ],
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test acc: 0.9221000075340271\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0h2mY-Mfdqmo",
        "colab_type": "text"
      },
      "source": [
        "# Computation graphs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BOLlkITkeEvK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@tf.function\n",
        "def gradient(img_batch, lbl_batch):\n",
        "  with tf.GradientTape() as tape:\n",
        "      logits = model(img_batch, training=True)\n",
        "        # loss format is generally: first argument targets, second argument outputs\n",
        "      xent = loss_fn(lbl_batch, logits)\n",
        "\n",
        "  varis = model.trainable_variables\n",
        "  grads = tape.gradient(xent, varis)\n",
        "  opt.apply_gradients(zip(grads, varis))\n",
        "  return logits,xent\n",
        "stamp = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "logdir = 'logs/func/%s' % stamp\n",
        "writer = tf.summary.create_file_writer(logdir)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZVBBLVTrPf8u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# tf.enable_eager_execution()\n",
        "\n",
        "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
        "\n",
        "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
        "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
        "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
        "data = tf.data.Dataset.from_tensor_slices(\n",
        "    (train_images.astype(np.float32) / 255.0, train_labels.astype(np.int32)))\n",
        "data = data.batch(128)\n",
        "\n",
        "# note: we batch the test data, but do not shuffle/repeat\n",
        "test_data = tf.data.Dataset.from_tensor_slices(\n",
        "    (test_images.astype(np.float32) / 255.0, test_labels.astype(np.int32))).batch(128)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iKLNdYNvd58Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epochs = 10\n",
        "n_h = 256\n",
        "model = models.Sequential([\n",
        "              layers.Conv2D(32, 3, padding= 'same' , activation= 'relu', input_shape = (28, 28, 1) ,  kernel_initializer= 'he_uniform'),\n",
        "              layers.BatchNormalization(),\n",
        "              layers.Conv2D(32, 3 , padding= 'same', activation = 'relu',  kernel_initializer= 'he_uniform'),\n",
        "              layers.BatchNormalization(),\n",
        "              layers.MaxPooling2D(),\n",
        "              layers.Dropout((0.3)),\n",
        "\n",
        "              layers.Conv2D(64, 3 , padding= 'same', activation = 'relu' ,  kernel_initializer= 'he_uniform'),\n",
        "              layers.BatchNormalization(),\n",
        "              layers.Conv2D(64, 3 , padding= 'same', activation = 'relu' ,  kernel_initializer= 'he_uniform'),\n",
        "              layers.BatchNormalization(),\n",
        "              layers.MaxPooling2D(),\n",
        "              layers.Dropout((0.4)),\n",
        "\n",
        "              layers.Conv2D(128, 3, padding= 'same', activation= 'relu' ,  kernel_initializer= 'he_uniform'),\n",
        "              layers.BatchNormalization(),\n",
        "              layers.Conv2D(128, 3, padding= 'same', activation= 'relu' ,  kernel_initializer= 'he_uniform'),\n",
        "              layers.BatchNormalization(),\n",
        "              layers.MaxPooling2D(),\n",
        "              layers.Dropout((0.5)),\n",
        "\n",
        "              layers.Flatten(),\n",
        "              layers.Dense(n_h, activation='relu' , kernel_initializer= 'he_uniform'),\n",
        "              layers.BatchNormalization(),\n",
        "              layers.Dense(n_h//2, activation='relu' , kernel_initializer= 'he_uniform'),\n",
        "              layers.Dense(10)\n",
        "              ])\n",
        "\n",
        "#model.build((None, 784))  # optional -- note None for the batch axis!!\n",
        "opt = tf.optimizers.Adam(learning_rate= 5 * 1e-3)\n",
        "# from_logits = True!! #neverforget\n",
        "loss_fn = tf.losses.SparseCategoricalCrossentropy(from_logits=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SXAbRKsanIAE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Clear any logs from previous runs\n",
        "!rm -rf ./logs/ "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c0ZQftBaeSv1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "afc5552d-1ff3-4367-bc29-040732fc3079"
      },
      "source": [
        "# train_acc_metric = tf.keras.metrics.SparseCategoricalAccuracy()\n",
        "for step , (img_batch, lbl_batch) in enumerate(data):\n",
        "  tf.summary.trace_on(graph=True, profiler=True)\n",
        "  logits,xent = gradient(img_batch, lbl_batch)\n",
        "  # train_acc_metric(lbl_batch, logits)\n",
        "  with writer.as_default():\n",
        "    tf.summary.trace_export(name=\"my_func_trace\",step=0,profiler_outdir=logdir)\n",
        "  # tf.print(\"Loss: {} Accuracy: {}\".format(xent, train_acc_metric.result()))\n",
        "  # train_acc_metric.reset_states()"
      ],
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Trace already enabled\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6AozeabGejT4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # Load the TensorBoard notebook extension.\n",
        "# %reload_ext tensorboard"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-o3CUq8Ueewt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# %tensorboard --logdir logs/func"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q9R1Qj9zZLmF",
        "colab_type": "text"
      },
      "source": [
        "# DenseNet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "74aKeIE9ZPl1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow.keras\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten, Input, AveragePooling2D, Activation\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
        "from tensorflow.keras.layers import Concatenate\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import regularizers\n",
        "# tf.keras.backend.clear_session()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uzgr6saXFyO8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Setting up the hyper parameters\n",
        "batch_size = 128\n",
        "number_classes = 10\n",
        "l = 5  #growth rate\n",
        "number_filters = 36\n",
        "compression = 0.5\n",
        "dropout = 0.2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xWVVSifW8ZGM",
        "colab_type": "code",
        "outputId": "79a2bea1-fe33-44d7-a32c-efe3cb674672",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Load the data\n",
        "(train_images,train_labels) , (test_images,test_labels) = cifar10.load_data()\n",
        "image_width = train_images.shape[1]\n",
        "image_height = train_images.shape[2]\n",
        "number_channels = train_images.shape[3]\n",
        "\n",
        "train_labels = tf.keras.utils.to_categorical(train_labels, num_classes= number_classes)\n",
        "test_labels = tf.keras.utils.to_categorical(test_labels, num_classes= number_classes)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 11s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IlLXed_U-8_Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def dense_block(input, number_filters = 12, dropout = 0.2, scope = ''):\n",
        "  x = input\n",
        "  for i in range(1, l+1):\n",
        "\n",
        "    # BN and Activation for last layer\n",
        "    BatchNorm_BN = BatchNormalization(name=scope+'_layer_'+ str(i-1) +'_BN_'+str(i-1))(x)    \n",
        "    relu_BN = Activation('relu', name=scope+'_layer_'+ str(i-1) +'_Relu_'+str(i-1))(BatchNorm_BN)  \n",
        "    \n",
        "    # Applying BottleNeck layer\n",
        "    Conv2D_1 = Conv2D(int(number_filters), 1, padding='same',kernel_initializer='he_uniform', name=scope+'_BotNec_'+str(i))(relu_BN)\n",
        "    BatchNorm = BatchNormalization(name=scope+'_BotNec_BN_'+str(i))(Conv2D_1)\n",
        "    relu = Activation('relu', name=scope+'_BotNec_Relu_'+str(i))(BatchNorm)\n",
        "\n",
        "    # Applying Conv layer\n",
        "    Conv2D_3 = Conv2D(int(number_filters), 3, padding='same', kernel_initializer='he_uniform', name=scope+'_layer_'+str(i))(relu)\n",
        "    # Conv2D_3 = Dropout(dropout, name=scope+'_Layer_'+ str(i) +'_Drop_'+str(i))(Conv2D_3)\n",
        "    \n",
        "    concat = Concatenate(axis=-1)([x,Conv2D_3])\n",
        "    x = concat\n",
        "  return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EdtpESxtB-EK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def transition_layer(input,number_filters = 12,dropout = 0.2, scope = ''):\n",
        "  BatchNorm = BatchNormalization(name=scope+'_BN')(input)\n",
        "  relu = Activation('relu', name=scope+\"_Relu\")(BatchNorm)\n",
        "  Conv2D_TL = Conv2D(int(number_filters * compression), 1, padding='same', kernel_initializer='he_uniform', name=scope+'_Conv')(relu)\n",
        "  # Conv2D_TL = Dropout(dropout, name=scope+'_Drop')(Conv2D_TL)\n",
        "  avg_pool = AveragePooling2D(pool_size=(2,2),strides=(2,2), name=scope+'_AVG_POOL')(Conv2D_TL)\n",
        "  return avg_pool"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0se8ZoosGd6E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def output_layer(input, scope):\n",
        "  BatchNorm = BatchNormalization(name=scope+'_BN')(input)\n",
        "  relu = Activation('relu', name=scope+'_Relu')(BatchNorm)\n",
        "  avg_pool = AveragePooling2D(pool_size=(2,2), name=scope+'_AVG_POOL')(relu)\n",
        "  temp = Conv2D(number_classes, 2, name=scope+'_Conv')(avg_pool)\n",
        "  output = Activation('softmax', name=scope+'_Softmax')(temp)\n",
        "  Flat = Flatten(name=scope+'_Flat')(output)\n",
        "  return Flat\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7hImV5q9IQz2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input = Input(shape = (image_height,image_width,number_channels), name='Input')\n",
        "First_Conv2D = Conv2D(number_filters, 3, padding='same', name=\"Conv_0\")(input)\n",
        "\n",
        "First_Block = dense_block(First_Conv2D, number_filters, dropout, scope='DB_1')\n",
        "First_Transition = transition_layer(First_Block, number_filters, dropout, scope='TB_1')\n",
        "\n",
        "Second_Block = dense_block(First_Transition, number_filters, dropout, scope='DB_2')\n",
        "Second_Transition = transition_layer(Second_Block, number_filters, dropout, scope='TB_2')\n",
        "\n",
        "Third_Block = dense_block(Second_Transition, number_filters, dropout, scope='DB_3')\n",
        "Third_Transition = transition_layer(Third_Block, number_filters, dropout, scope='TB_3')\n",
        "\n",
        "Final_Block = dense_block(Third_Transition, number_filters, dropout, scope='FB')\n",
        "output = output_layer(Final_Block, scope='Output')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aBrVU2zFMKfR",
        "colab_type": "code",
        "outputId": "5b0dd3f1-e3d0-4677-d890-58c2170b9198",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model = Model(inputs = [input] , outputs = [output])\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "Input (InputLayer)              [(None, 32, 32, 3)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "Conv_0 (Conv2D)                 (None, 32, 32, 36)   1008        Input[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "DB_1_layer_0_BN_0 (BatchNormali (None, 32, 32, 36)   144         Conv_0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "DB_1_layer_0_Relu_0 (Activation (None, 32, 32, 36)   0           DB_1_layer_0_BN_0[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "DB_1_BotNec_1 (Conv2D)          (None, 32, 32, 36)   1332        DB_1_layer_0_Relu_0[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "DB_1_BotNec_BN_1 (BatchNormaliz (None, 32, 32, 36)   144         DB_1_BotNec_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "DB_1_BotNec_Relu_1 (Activation) (None, 32, 32, 36)   0           DB_1_BotNec_BN_1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "DB_1_layer_1 (Conv2D)           (None, 32, 32, 36)   11700       DB_1_BotNec_Relu_1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 32, 32, 72)   0           Conv_0[0][0]                     \n",
            "                                                                 DB_1_layer_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "DB_1_layer_1_BN_1 (BatchNormali (None, 32, 32, 72)   288         concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "DB_1_layer_1_Relu_1 (Activation (None, 32, 32, 72)   0           DB_1_layer_1_BN_1[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "DB_1_BotNec_2 (Conv2D)          (None, 32, 32, 36)   2628        DB_1_layer_1_Relu_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "DB_1_BotNec_BN_2 (BatchNormaliz (None, 32, 32, 36)   144         DB_1_BotNec_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "DB_1_BotNec_Relu_2 (Activation) (None, 32, 32, 36)   0           DB_1_BotNec_BN_2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "DB_1_layer_2 (Conv2D)           (None, 32, 32, 36)   11700       DB_1_BotNec_Relu_2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 32, 32, 108)  0           concatenate[0][0]                \n",
            "                                                                 DB_1_layer_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "DB_1_layer_2_BN_2 (BatchNormali (None, 32, 32, 108)  432         concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "DB_1_layer_2_Relu_2 (Activation (None, 32, 32, 108)  0           DB_1_layer_2_BN_2[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "DB_1_BotNec_3 (Conv2D)          (None, 32, 32, 36)   3924        DB_1_layer_2_Relu_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "DB_1_BotNec_BN_3 (BatchNormaliz (None, 32, 32, 36)   144         DB_1_BotNec_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "DB_1_BotNec_Relu_3 (Activation) (None, 32, 32, 36)   0           DB_1_BotNec_BN_3[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "DB_1_layer_3 (Conv2D)           (None, 32, 32, 36)   11700       DB_1_BotNec_Relu_3[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 32, 32, 144)  0           concatenate_1[0][0]              \n",
            "                                                                 DB_1_layer_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "DB_1_layer_3_BN_3 (BatchNormali (None, 32, 32, 144)  576         concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "DB_1_layer_3_Relu_3 (Activation (None, 32, 32, 144)  0           DB_1_layer_3_BN_3[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "DB_1_BotNec_4 (Conv2D)          (None, 32, 32, 36)   5220        DB_1_layer_3_Relu_3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "DB_1_BotNec_BN_4 (BatchNormaliz (None, 32, 32, 36)   144         DB_1_BotNec_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "DB_1_BotNec_Relu_4 (Activation) (None, 32, 32, 36)   0           DB_1_BotNec_BN_4[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "DB_1_layer_4 (Conv2D)           (None, 32, 32, 36)   11700       DB_1_BotNec_Relu_4[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 32, 32, 180)  0           concatenate_2[0][0]              \n",
            "                                                                 DB_1_layer_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "DB_1_layer_4_BN_4 (BatchNormali (None, 32, 32, 180)  720         concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "DB_1_layer_4_Relu_4 (Activation (None, 32, 32, 180)  0           DB_1_layer_4_BN_4[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "DB_1_BotNec_5 (Conv2D)          (None, 32, 32, 36)   6516        DB_1_layer_4_Relu_4[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "DB_1_BotNec_BN_5 (BatchNormaliz (None, 32, 32, 36)   144         DB_1_BotNec_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "DB_1_BotNec_Relu_5 (Activation) (None, 32, 32, 36)   0           DB_1_BotNec_BN_5[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "DB_1_layer_5 (Conv2D)           (None, 32, 32, 36)   11700       DB_1_BotNec_Relu_5[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_4 (Concatenate)     (None, 32, 32, 216)  0           concatenate_3[0][0]              \n",
            "                                                                 DB_1_layer_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "TB_1_BN (BatchNormalization)    (None, 32, 32, 216)  864         concatenate_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "TB_1_Relu (Activation)          (None, 32, 32, 216)  0           TB_1_BN[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "TB_1_Conv (Conv2D)              (None, 32, 32, 18)   3906        TB_1_Relu[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "TB_1_AVG_POOL (AveragePooling2D (None, 16, 16, 18)   0           TB_1_Conv[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "DB_2_layer_0_BN_0 (BatchNormali (None, 16, 16, 18)   72          TB_1_AVG_POOL[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "DB_2_layer_0_Relu_0 (Activation (None, 16, 16, 18)   0           DB_2_layer_0_BN_0[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "DB_2_BotNec_1 (Conv2D)          (None, 16, 16, 36)   684         DB_2_layer_0_Relu_0[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "DB_2_BotNec_BN_1 (BatchNormaliz (None, 16, 16, 36)   144         DB_2_BotNec_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "DB_2_BotNec_Relu_1 (Activation) (None, 16, 16, 36)   0           DB_2_BotNec_BN_1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "DB_2_layer_1 (Conv2D)           (None, 16, 16, 36)   11700       DB_2_BotNec_Relu_1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_5 (Concatenate)     (None, 16, 16, 54)   0           TB_1_AVG_POOL[0][0]              \n",
            "                                                                 DB_2_layer_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "DB_2_layer_1_BN_1 (BatchNormali (None, 16, 16, 54)   216         concatenate_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "DB_2_layer_1_Relu_1 (Activation (None, 16, 16, 54)   0           DB_2_layer_1_BN_1[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "DB_2_BotNec_2 (Conv2D)          (None, 16, 16, 36)   1980        DB_2_layer_1_Relu_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "DB_2_BotNec_BN_2 (BatchNormaliz (None, 16, 16, 36)   144         DB_2_BotNec_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "DB_2_BotNec_Relu_2 (Activation) (None, 16, 16, 36)   0           DB_2_BotNec_BN_2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "DB_2_layer_2 (Conv2D)           (None, 16, 16, 36)   11700       DB_2_BotNec_Relu_2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_6 (Concatenate)     (None, 16, 16, 90)   0           concatenate_5[0][0]              \n",
            "                                                                 DB_2_layer_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "DB_2_layer_2_BN_2 (BatchNormali (None, 16, 16, 90)   360         concatenate_6[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "DB_2_layer_2_Relu_2 (Activation (None, 16, 16, 90)   0           DB_2_layer_2_BN_2[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "DB_2_BotNec_3 (Conv2D)          (None, 16, 16, 36)   3276        DB_2_layer_2_Relu_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "DB_2_BotNec_BN_3 (BatchNormaliz (None, 16, 16, 36)   144         DB_2_BotNec_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "DB_2_BotNec_Relu_3 (Activation) (None, 16, 16, 36)   0           DB_2_BotNec_BN_3[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "DB_2_layer_3 (Conv2D)           (None, 16, 16, 36)   11700       DB_2_BotNec_Relu_3[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_7 (Concatenate)     (None, 16, 16, 126)  0           concatenate_6[0][0]              \n",
            "                                                                 DB_2_layer_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "DB_2_layer_3_BN_3 (BatchNormali (None, 16, 16, 126)  504         concatenate_7[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "DB_2_layer_3_Relu_3 (Activation (None, 16, 16, 126)  0           DB_2_layer_3_BN_3[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "DB_2_BotNec_4 (Conv2D)          (None, 16, 16, 36)   4572        DB_2_layer_3_Relu_3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "DB_2_BotNec_BN_4 (BatchNormaliz (None, 16, 16, 36)   144         DB_2_BotNec_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "DB_2_BotNec_Relu_4 (Activation) (None, 16, 16, 36)   0           DB_2_BotNec_BN_4[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "DB_2_layer_4 (Conv2D)           (None, 16, 16, 36)   11700       DB_2_BotNec_Relu_4[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_8 (Concatenate)     (None, 16, 16, 162)  0           concatenate_7[0][0]              \n",
            "                                                                 DB_2_layer_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "DB_2_layer_4_BN_4 (BatchNormali (None, 16, 16, 162)  648         concatenate_8[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "DB_2_layer_4_Relu_4 (Activation (None, 16, 16, 162)  0           DB_2_layer_4_BN_4[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "DB_2_BotNec_5 (Conv2D)          (None, 16, 16, 36)   5868        DB_2_layer_4_Relu_4[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "DB_2_BotNec_BN_5 (BatchNormaliz (None, 16, 16, 36)   144         DB_2_BotNec_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "DB_2_BotNec_Relu_5 (Activation) (None, 16, 16, 36)   0           DB_2_BotNec_BN_5[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "DB_2_layer_5 (Conv2D)           (None, 16, 16, 36)   11700       DB_2_BotNec_Relu_5[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_9 (Concatenate)     (None, 16, 16, 198)  0           concatenate_8[0][0]              \n",
            "                                                                 DB_2_layer_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "TB_2_BN (BatchNormalization)    (None, 16, 16, 198)  792         concatenate_9[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "TB_2_Relu (Activation)          (None, 16, 16, 198)  0           TB_2_BN[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "TB_2_Conv (Conv2D)              (None, 16, 16, 18)   3582        TB_2_Relu[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "TB_2_AVG_POOL (AveragePooling2D (None, 8, 8, 18)     0           TB_2_Conv[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "DB_3_layer_0_BN_0 (BatchNormali (None, 8, 8, 18)     72          TB_2_AVG_POOL[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "DB_3_layer_0_Relu_0 (Activation (None, 8, 8, 18)     0           DB_3_layer_0_BN_0[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "DB_3_BotNec_1 (Conv2D)          (None, 8, 8, 36)     684         DB_3_layer_0_Relu_0[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "DB_3_BotNec_BN_1 (BatchNormaliz (None, 8, 8, 36)     144         DB_3_BotNec_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "DB_3_BotNec_Relu_1 (Activation) (None, 8, 8, 36)     0           DB_3_BotNec_BN_1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "DB_3_layer_1 (Conv2D)           (None, 8, 8, 36)     11700       DB_3_BotNec_Relu_1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_10 (Concatenate)    (None, 8, 8, 54)     0           TB_2_AVG_POOL[0][0]              \n",
            "                                                                 DB_3_layer_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "DB_3_layer_1_BN_1 (BatchNormali (None, 8, 8, 54)     216         concatenate_10[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "DB_3_layer_1_Relu_1 (Activation (None, 8, 8, 54)     0           DB_3_layer_1_BN_1[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "DB_3_BotNec_2 (Conv2D)          (None, 8, 8, 36)     1980        DB_3_layer_1_Relu_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "DB_3_BotNec_BN_2 (BatchNormaliz (None, 8, 8, 36)     144         DB_3_BotNec_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "DB_3_BotNec_Relu_2 (Activation) (None, 8, 8, 36)     0           DB_3_BotNec_BN_2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "DB_3_layer_2 (Conv2D)           (None, 8, 8, 36)     11700       DB_3_BotNec_Relu_2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_11 (Concatenate)    (None, 8, 8, 90)     0           concatenate_10[0][0]             \n",
            "                                                                 DB_3_layer_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "DB_3_layer_2_BN_2 (BatchNormali (None, 8, 8, 90)     360         concatenate_11[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "DB_3_layer_2_Relu_2 (Activation (None, 8, 8, 90)     0           DB_3_layer_2_BN_2[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "DB_3_BotNec_3 (Conv2D)          (None, 8, 8, 36)     3276        DB_3_layer_2_Relu_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "DB_3_BotNec_BN_3 (BatchNormaliz (None, 8, 8, 36)     144         DB_3_BotNec_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "DB_3_BotNec_Relu_3 (Activation) (None, 8, 8, 36)     0           DB_3_BotNec_BN_3[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "DB_3_layer_3 (Conv2D)           (None, 8, 8, 36)     11700       DB_3_BotNec_Relu_3[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_12 (Concatenate)    (None, 8, 8, 126)    0           concatenate_11[0][0]             \n",
            "                                                                 DB_3_layer_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "DB_3_layer_3_BN_3 (BatchNormali (None, 8, 8, 126)    504         concatenate_12[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "DB_3_layer_3_Relu_3 (Activation (None, 8, 8, 126)    0           DB_3_layer_3_BN_3[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "DB_3_BotNec_4 (Conv2D)          (None, 8, 8, 36)     4572        DB_3_layer_3_Relu_3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "DB_3_BotNec_BN_4 (BatchNormaliz (None, 8, 8, 36)     144         DB_3_BotNec_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "DB_3_BotNec_Relu_4 (Activation) (None, 8, 8, 36)     0           DB_3_BotNec_BN_4[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "DB_3_layer_4 (Conv2D)           (None, 8, 8, 36)     11700       DB_3_BotNec_Relu_4[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_13 (Concatenate)    (None, 8, 8, 162)    0           concatenate_12[0][0]             \n",
            "                                                                 DB_3_layer_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "DB_3_layer_4_BN_4 (BatchNormali (None, 8, 8, 162)    648         concatenate_13[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "DB_3_layer_4_Relu_4 (Activation (None, 8, 8, 162)    0           DB_3_layer_4_BN_4[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "DB_3_BotNec_5 (Conv2D)          (None, 8, 8, 36)     5868        DB_3_layer_4_Relu_4[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "DB_3_BotNec_BN_5 (BatchNormaliz (None, 8, 8, 36)     144         DB_3_BotNec_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "DB_3_BotNec_Relu_5 (Activation) (None, 8, 8, 36)     0           DB_3_BotNec_BN_5[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "DB_3_layer_5 (Conv2D)           (None, 8, 8, 36)     11700       DB_3_BotNec_Relu_5[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_14 (Concatenate)    (None, 8, 8, 198)    0           concatenate_13[0][0]             \n",
            "                                                                 DB_3_layer_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "TB_3_BN (BatchNormalization)    (None, 8, 8, 198)    792         concatenate_14[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "TB_3_Relu (Activation)          (None, 8, 8, 198)    0           TB_3_BN[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "TB_3_Conv (Conv2D)              (None, 8, 8, 18)     3582        TB_3_Relu[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "TB_3_AVG_POOL (AveragePooling2D (None, 4, 4, 18)     0           TB_3_Conv[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "FB_layer_0_BN_0 (BatchNormaliza (None, 4, 4, 18)     72          TB_3_AVG_POOL[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "FB_layer_0_Relu_0 (Activation)  (None, 4, 4, 18)     0           FB_layer_0_BN_0[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "FB_BotNec_1 (Conv2D)            (None, 4, 4, 36)     684         FB_layer_0_Relu_0[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "FB_BotNec_BN_1 (BatchNormalizat (None, 4, 4, 36)     144         FB_BotNec_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "FB_BotNec_Relu_1 (Activation)   (None, 4, 4, 36)     0           FB_BotNec_BN_1[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "FB_layer_1 (Conv2D)             (None, 4, 4, 36)     11700       FB_BotNec_Relu_1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_15 (Concatenate)    (None, 4, 4, 54)     0           TB_3_AVG_POOL[0][0]              \n",
            "                                                                 FB_layer_1[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "FB_layer_1_BN_1 (BatchNormaliza (None, 4, 4, 54)     216         concatenate_15[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "FB_layer_1_Relu_1 (Activation)  (None, 4, 4, 54)     0           FB_layer_1_BN_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "FB_BotNec_2 (Conv2D)            (None, 4, 4, 36)     1980        FB_layer_1_Relu_1[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "FB_BotNec_BN_2 (BatchNormalizat (None, 4, 4, 36)     144         FB_BotNec_2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "FB_BotNec_Relu_2 (Activation)   (None, 4, 4, 36)     0           FB_BotNec_BN_2[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "FB_layer_2 (Conv2D)             (None, 4, 4, 36)     11700       FB_BotNec_Relu_2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_16 (Concatenate)    (None, 4, 4, 90)     0           concatenate_15[0][0]             \n",
            "                                                                 FB_layer_2[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "FB_layer_2_BN_2 (BatchNormaliza (None, 4, 4, 90)     360         concatenate_16[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "FB_layer_2_Relu_2 (Activation)  (None, 4, 4, 90)     0           FB_layer_2_BN_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "FB_BotNec_3 (Conv2D)            (None, 4, 4, 36)     3276        FB_layer_2_Relu_2[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "FB_BotNec_BN_3 (BatchNormalizat (None, 4, 4, 36)     144         FB_BotNec_3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "FB_BotNec_Relu_3 (Activation)   (None, 4, 4, 36)     0           FB_BotNec_BN_3[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "FB_layer_3 (Conv2D)             (None, 4, 4, 36)     11700       FB_BotNec_Relu_3[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_17 (Concatenate)    (None, 4, 4, 126)    0           concatenate_16[0][0]             \n",
            "                                                                 FB_layer_3[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "FB_layer_3_BN_3 (BatchNormaliza (None, 4, 4, 126)    504         concatenate_17[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "FB_layer_3_Relu_3 (Activation)  (None, 4, 4, 126)    0           FB_layer_3_BN_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "FB_BotNec_4 (Conv2D)            (None, 4, 4, 36)     4572        FB_layer_3_Relu_3[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "FB_BotNec_BN_4 (BatchNormalizat (None, 4, 4, 36)     144         FB_BotNec_4[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "FB_BotNec_Relu_4 (Activation)   (None, 4, 4, 36)     0           FB_BotNec_BN_4[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "FB_layer_4 (Conv2D)             (None, 4, 4, 36)     11700       FB_BotNec_Relu_4[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_18 (Concatenate)    (None, 4, 4, 162)    0           concatenate_17[0][0]             \n",
            "                                                                 FB_layer_4[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "FB_layer_4_BN_4 (BatchNormaliza (None, 4, 4, 162)    648         concatenate_18[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "FB_layer_4_Relu_4 (Activation)  (None, 4, 4, 162)    0           FB_layer_4_BN_4[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "FB_BotNec_5 (Conv2D)            (None, 4, 4, 36)     5868        FB_layer_4_Relu_4[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "FB_BotNec_BN_5 (BatchNormalizat (None, 4, 4, 36)     144         FB_BotNec_5[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "FB_BotNec_Relu_5 (Activation)   (None, 4, 4, 36)     0           FB_BotNec_BN_5[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "FB_layer_5 (Conv2D)             (None, 4, 4, 36)     11700       FB_BotNec_Relu_5[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_19 (Concatenate)    (None, 4, 4, 198)    0           concatenate_18[0][0]             \n",
            "                                                                 FB_layer_5[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "Output_BN (BatchNormalization)  (None, 4, 4, 198)    792         concatenate_19[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "Output_Relu (Activation)        (None, 4, 4, 198)    0           Output_BN[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "Output_AVG_POOL (AveragePooling (None, 2, 2, 198)    0           Output_Relu[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "Output_Conv (Conv2D)            (None, 1, 1, 10)     7930        Output_AVG_POOL[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "Output_Softmax (Activation)     (None, 1, 1, 10)     0           Output_Conv[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "Output_Flat (Flatten)           (None, 10)           0           Output_Softmax[0][0]             \n",
            "==================================================================================================\n",
            "Total params: 336,448\n",
            "Trainable params: 329,608\n",
            "Non-trainable params: 6,840\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yqZYlaDwQ_lp",
        "colab_type": "code",
        "outputId": "a0403db5-5ee0-4ddd-f568-40ac0b60576d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "datagen = ImageDataGenerator(rotation_range = 15, horizontal_flip = True, width_shift_range = 0.1, height_shift_range = 0.1, zoom_range = 0.2, shear_range = 15)\n",
        "datagen.fit(train_images)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sFtfQmMhSGhb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss='categorical_crossentropy',optimizer=Adam(0.005),metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wei2OmgzTaXL",
        "colab_type": "code",
        "outputId": "0a5c1baf-9466-4fb6-81ab-e0850af16edb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.fit(datagen.flow(train_images, train_labels, batch_size), steps_per_epoch = 3*train_images.shape[0]/batch_size, \n",
        "                    epochs = 40 ,validation_data =(test_images, test_labels))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            "1172/1171 [==============================] - 293s 250ms/step - loss: 1.4622 - accuracy: 0.4778 - val_loss: 1.6217 - val_accuracy: 0.5207\n",
            "Epoch 2/40\n",
            "1172/1171 [==============================] - 291s 248ms/step - loss: 0.9266 - accuracy: 0.6715 - val_loss: 1.3761 - val_accuracy: 0.6036\n",
            "Epoch 3/40\n",
            "1172/1171 [==============================] - 290s 247ms/step - loss: 0.7222 - accuracy: 0.7459 - val_loss: 1.0623 - val_accuracy: 0.6877\n",
            "Epoch 4/40\n",
            "1172/1171 [==============================] - 289s 247ms/step - loss: 0.6046 - accuracy: 0.7895 - val_loss: 0.6625 - val_accuracy: 0.7786\n",
            "Epoch 5/40\n",
            "1172/1171 [==============================] - 289s 247ms/step - loss: 0.5349 - accuracy: 0.8133 - val_loss: 0.6126 - val_accuracy: 0.7968\n",
            "Epoch 6/40\n",
            "1172/1171 [==============================] - 290s 247ms/step - loss: 0.4798 - accuracy: 0.8324 - val_loss: 0.6565 - val_accuracy: 0.7932\n",
            "Epoch 7/40\n",
            "1172/1171 [==============================] - 290s 247ms/step - loss: 0.4398 - accuracy: 0.8475 - val_loss: 0.6579 - val_accuracy: 0.7932\n",
            "Epoch 8/40\n",
            "1172/1171 [==============================] - 290s 247ms/step - loss: 0.4085 - accuracy: 0.8583 - val_loss: 0.5754 - val_accuracy: 0.8151\n",
            "Epoch 9/40\n",
            "1172/1171 [==============================] - 290s 247ms/step - loss: 0.3845 - accuracy: 0.8662 - val_loss: 0.5651 - val_accuracy: 0.8270\n",
            "Epoch 10/40\n",
            "1172/1171 [==============================] - 290s 247ms/step - loss: 0.3601 - accuracy: 0.8750 - val_loss: 0.4070 - val_accuracy: 0.8658\n",
            "Epoch 11/40\n",
            "1172/1171 [==============================] - 290s 247ms/step - loss: 0.3410 - accuracy: 0.8818 - val_loss: 0.6987 - val_accuracy: 0.8011\n",
            "Epoch 12/40\n",
            "1172/1171 [==============================] - 290s 247ms/step - loss: 0.3243 - accuracy: 0.8869 - val_loss: 0.4787 - val_accuracy: 0.8565\n",
            "Epoch 13/40\n",
            "1172/1171 [==============================] - 290s 247ms/step - loss: 0.3101 - accuracy: 0.8922 - val_loss: 0.5863 - val_accuracy: 0.8282\n",
            "Epoch 14/40\n",
            "1172/1171 [==============================] - 290s 247ms/step - loss: 0.2955 - accuracy: 0.8970 - val_loss: 0.5090 - val_accuracy: 0.8465\n",
            "Epoch 15/40\n",
            "1172/1171 [==============================] - 290s 247ms/step - loss: 0.2864 - accuracy: 0.9004 - val_loss: 0.4568 - val_accuracy: 0.8624\n",
            "Epoch 16/40\n",
            "1172/1171 [==============================] - 290s 247ms/step - loss: 0.2743 - accuracy: 0.9038 - val_loss: 0.4343 - val_accuracy: 0.8642\n",
            "Epoch 17/40\n",
            "1172/1171 [==============================] - 290s 248ms/step - loss: 0.2657 - accuracy: 0.9061 - val_loss: 0.4820 - val_accuracy: 0.8616\n",
            "Epoch 18/40\n",
            "1172/1171 [==============================] - 291s 248ms/step - loss: 0.2571 - accuracy: 0.9096 - val_loss: 0.4414 - val_accuracy: 0.8683\n",
            "Epoch 19/40\n",
            "1172/1171 [==============================] - 290s 248ms/step - loss: 0.2475 - accuracy: 0.9130 - val_loss: 0.5108 - val_accuracy: 0.8611\n",
            "Epoch 20/40\n",
            "1172/1171 [==============================] - 291s 248ms/step - loss: 0.2398 - accuracy: 0.9151 - val_loss: 0.3768 - val_accuracy: 0.8850\n",
            "Epoch 21/40\n",
            "1172/1171 [==============================] - 290s 247ms/step - loss: 0.2336 - accuracy: 0.9179 - val_loss: 0.3697 - val_accuracy: 0.8876\n",
            "Epoch 22/40\n",
            "1172/1171 [==============================] - 288s 246ms/step - loss: 0.2260 - accuracy: 0.9203 - val_loss: 0.3773 - val_accuracy: 0.8866\n",
            "Epoch 23/40\n",
            "1172/1171 [==============================] - 287s 245ms/step - loss: 0.2194 - accuracy: 0.9220 - val_loss: 0.4068 - val_accuracy: 0.8838\n",
            "Epoch 24/40\n",
            "1172/1171 [==============================] - 289s 246ms/step - loss: 0.2134 - accuracy: 0.9248 - val_loss: 0.5184 - val_accuracy: 0.8665\n",
            "Epoch 25/40\n",
            "1172/1171 [==============================] - 291s 248ms/step - loss: 0.2091 - accuracy: 0.9264 - val_loss: 0.4356 - val_accuracy: 0.8776\n",
            "Epoch 26/40\n",
            "1172/1171 [==============================] - 291s 248ms/step - loss: 0.2052 - accuracy: 0.9278 - val_loss: 0.4861 - val_accuracy: 0.8619\n",
            "Epoch 27/40\n",
            "1172/1171 [==============================] - 289s 246ms/step - loss: 0.2001 - accuracy: 0.9298 - val_loss: 0.4326 - val_accuracy: 0.8766\n",
            "Epoch 28/40\n",
            "1172/1171 [==============================] - 288s 246ms/step - loss: 0.1961 - accuracy: 0.9309 - val_loss: 0.4334 - val_accuracy: 0.8781\n",
            "Epoch 29/40\n",
            "1172/1171 [==============================] - 288s 246ms/step - loss: 0.1911 - accuracy: 0.9326 - val_loss: 0.4396 - val_accuracy: 0.8800\n",
            "Epoch 30/40\n",
            "1172/1171 [==============================] - 291s 248ms/step - loss: 0.1901 - accuracy: 0.9334 - val_loss: 0.3758 - val_accuracy: 0.8932\n",
            "Epoch 31/40\n",
            "1172/1171 [==============================] - 291s 248ms/step - loss: 0.1835 - accuracy: 0.9354 - val_loss: 0.4274 - val_accuracy: 0.8819\n",
            "Epoch 32/40\n",
            "1172/1171 [==============================] - 290s 247ms/step - loss: 0.1790 - accuracy: 0.9368 - val_loss: 0.3565 - val_accuracy: 0.8977\n",
            "Epoch 33/40\n",
            "1172/1171 [==============================] - 288s 246ms/step - loss: 0.1770 - accuracy: 0.9376 - val_loss: 0.4711 - val_accuracy: 0.8735\n",
            "Epoch 34/40\n",
            "1172/1171 [==============================] - 288s 246ms/step - loss: 0.1739 - accuracy: 0.9384 - val_loss: 0.5268 - val_accuracy: 0.8630\n",
            "Epoch 35/40\n",
            "1172/1171 [==============================] - 290s 247ms/step - loss: 0.1683 - accuracy: 0.9405 - val_loss: 0.3452 - val_accuracy: 0.9021\n",
            "Epoch 36/40\n",
            "1172/1171 [==============================] - 291s 248ms/step - loss: 0.1658 - accuracy: 0.9413 - val_loss: 0.4148 - val_accuracy: 0.8875\n",
            "Epoch 37/40\n",
            "1172/1171 [==============================] - 291s 248ms/step - loss: 0.1639 - accuracy: 0.9421 - val_loss: 0.3898 - val_accuracy: 0.8931\n",
            "Epoch 38/40\n",
            "1172/1171 [==============================] - 289s 247ms/step - loss: 0.1607 - accuracy: 0.9436 - val_loss: 0.5601 - val_accuracy: 0.8628\n",
            "Epoch 39/40\n",
            "1172/1171 [==============================] - 289s 247ms/step - loss: 0.1620 - accuracy: 0.9429 - val_loss: 0.5155 - val_accuracy: 0.8717\n",
            "Epoch 40/40\n",
            "1172/1171 [==============================] - 289s 247ms/step - loss: 0.1544 - accuracy: 0.9447 - val_loss: 0.4763 - val_accuracy: 0.8788\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f2b6cc535c0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eSZYwtS0WqZw",
        "colab_type": "code",
        "outputId": "dc6ff9d2-53c0-4a8e-afaa-e65b75540325",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "model.evaluate(test_images,test_labels)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 7s 21ms/step - loss: 0.4763 - accuracy: 0.8788\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.4762791395187378, 0.8787999749183655]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y2aHxaRfAofN",
        "colab_type": "text"
      },
      "source": [
        "* We have build network with 4 dense blocks and 3 transition layers and then one output layer. With growth rate equal to 5 , learning rate as 0.005 ,no dropout and with data augmentation we were able to achieve test accuracy of 90.21% at 35th epoch. \n",
        "* Where as with growth rate as 8 , learning rate as 0.001, with dropout as 0.4 and without data augmentation test accuracy was around 86.7% at 23rd epoch.\n",
        "* If we increase growth rate to 12, we might get better test accuracy.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ]
}