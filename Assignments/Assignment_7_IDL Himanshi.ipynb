{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment 7 IDL.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "13hswk_OT26H",
        "Lk_WvOdpaWag",
        "RE0yQ3msmiYD",
        "c4rsSmjzDf68",
        "b0O1y7OJDvmx",
        "kBWJmKb5SuuL",
        "QFquJg1dUZNv",
        "Fw3T_F0cYffC"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tIHQkV7nkP3Y",
        "colab_type": "text"
      },
      "source": [
        "GROUP MEMBERS :\n",
        "1.  Aniruddh Shukla \n",
        "2. Gaurav Singhal \n",
        "3. Himanshi Bajaj "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "829GH2XrS28Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.chdir(\"/content/drive/My Drive/Colab Notebooks\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TEXlUSjnTLmO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "13hswk_OT26H",
        "colab_type": "text"
      },
      "source": [
        "# Task 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "osm7TKGVTTGY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@tf.function\n",
        "def task1(twoDarr,k):\n",
        "  tf.print(\"================= 2D Tensor of shape (?,n) before calculating top k values =================== \\n\")\n",
        "  tf.print(twoDarr)\n",
        "  newarr = tf.math.top_k(twoDarr,k=k)\n",
        "  return newarr"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k-F0wyUZVpRt",
        "colab_type": "code",
        "outputId": "89e543a5-7617-4422-c7a1-822a69a74e39",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "twoDarr = tf.random.uniform((4,6),minval=5,maxval=50,dtype=tf.dtypes.int32)\n",
        "k = 5\n",
        "output = task1(twoDarr,k)\n",
        "tf.print(\"\\n ================= 2D Tensor of shape (?,k) after calculating top k values =================== \\n\")\n",
        "tf.print(output.values)\n",
        "tf.print(\"\\n ================= Indices of resultant tensor =================== \\n\")\n",
        "tf.print(output.indices)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "================= 2D Tensor of shape (?,n) before calculating top k values =================== \n",
            "\n",
            "[[26 12 48 45 14 31]\n",
            " [25 41 45 31 41 48]\n",
            " [36 30 35 6 15 30]\n",
            " [45 24 38 9 22 17]]\n",
            "\n",
            " ================= 2D Tensor of shape (?,k) after calculating top k values =================== \n",
            "\n",
            "[[48 45 31 26 14]\n",
            " [48 45 41 41 31]\n",
            " [36 35 30 30 15]\n",
            " [45 38 24 22 17]]\n",
            "\n",
            " ================= Indices of resultant tensor =================== \n",
            "\n",
            "[[2 3 5 0 4]\n",
            " [5 2 1 4 3]\n",
            " [0 2 1 5 4]\n",
            " [0 2 1 4 5]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lk_WvOdpaWag",
        "colab_type": "text"
      },
      "source": [
        "# Task 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qXEU--6SaYOo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@tf.function\n",
        "def task2(twoDarr):\n",
        "  tf.random.set_seed(10)\n",
        "  tf.print(\"================= 2D Tensor of shape (?,n) before calculating argmax =================== \\n\")\n",
        "  tf.print(twoDarr)\n",
        "  newarr = tf.argmax(twoDarr,axis=1)\n",
        "  return newarr"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XTAvikJpbmBC",
        "colab_type": "code",
        "outputId": "a2b0c371-2085-404a-e2d0-4145cc63600e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "twoDarr = tf.random.uniform((4,5),minval=5,maxval=50,dtype=tf.dtypes.int32)\n",
        "output = task2(twoDarr)\n",
        "tf.print(\"\\n ================= After calculating argmax =================== \\n\")\n",
        "tf.print(output)\n",
        "tf.print(\"\\n ================= 2D Tensor of shape (?,n) with 0 and 1 =================== \\n\")\n",
        "depth = twoDarr.get_shape()\n",
        "output = tf.one_hot(output,depth=depth[1])\n",
        "tf.print(output)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "================= 2D Tensor of shape (?,n) before calculating argmax =================== \n",
            "\n",
            "[[22 14 31 32 37]\n",
            " [14 46 38 40 13]\n",
            " [24 5 15 47 48]\n",
            " [12 17 5 28 20]]\n",
            "\n",
            " ================= after calculating argmax =================== \n",
            "\n",
            "[4 1 4 3]\n",
            "\n",
            " ================= 2D Tensor of shape (?,n) with 0 and 1 =================== \n",
            "\n",
            "[[0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 0 0 1 0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RE0yQ3msmiYD",
        "colab_type": "text"
      },
      "source": [
        "# Task 3 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CnG7SHUImko0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@tf.function\n",
        "def task3(twoDarr,k):\n",
        "  newarr = tf.math.top_k(twoDarr,k=k)\n",
        "  idxs = tf.expand_dims(newarr.indices,axis=1)\n",
        "  # tf.print(idxs.shape)\n",
        "  vals = newarr.values\n",
        "  # tf.print(idxs,vals)\n",
        "  scatter = tf.scatter_nd(indices=idxs,updates=vals,shape=twoDarr.shape)\n",
        "  return scatter"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HYvGE9BcmpkT",
        "colab_type": "code",
        "outputId": "b1fb19da-df12-4b6a-a0d2-06ca36b8f002",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "twoDarr = tf.random.uniform((6,),minval=5,maxval=50,dtype=tf.dtypes.int32)\n",
        "k = 3\n",
        "tf.print(\"================= 1D Tensor of shape (n,) before calculating top k values =================== \\n\")\n",
        "tf.print(twoDarr)\n",
        "scatter = task3(twoDarr,k)\n",
        "tf.print(\"\\n ================= 1D Tensor of shape (n,) after calculating top k values and scatter =================== \\n\")\n",
        "tf.print(scatter)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "================= 1D Tensor of shape (n,) before calculating top k values =================== \n",
            "\n",
            "[23 40 21 40 43 12]\n",
            "\n",
            " ================= 1D Tensor of shape (n,) after calculating top k values and scatter =================== \n",
            "\n",
            "[0 40 0 40 43 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fXLgnh94LTZI",
        "colab_type": "text"
      },
      "source": [
        "**Bonus**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EGuiGaDrhGRo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# source https://stackoverflow.com/questions/52996505/using-scatter-nd-with-top-k-output\n",
        "@tf.function\n",
        "def task3(twoDarr,k):\n",
        "\n",
        "  newarr = tf.math.top_k(twoDarr,k=k)\n",
        "  idxs = newarr.indices\n",
        "  vals = newarr.values\n",
        "\n",
        "  # tf.print(idxs.shape)\n",
        "  # tf.print(vals.shape)\n",
        "  # tf.print(\"\\n\\n\",idxs,\"\\n\\n\",vals)\n",
        "\n",
        "  num_rows = twoDarr.shape[0]\n",
        "  row_range = tf.range(num_rows)\n",
        "  tensor_row = tf.tile(row_range[:,None], (1, k))\n",
        "\n",
        "  # tf.print(\"\\n\",num_rows)\n",
        "  # tf.print(\"\\n\",row_range)\n",
        "  # tf.print(\"\\n\",row_tensor)\n",
        "\n",
        "  top_k_row_col_idxs = tf.stack([tensor_row, idxs], axis=2)\n",
        "  # tf.print(\"\\n\",top_k_row_col_indices)\n",
        "\n",
        "  updates = tf.ones([num_rows, k], dtype=tf.int32)\n",
        "  # tf.print(\"\\n\",updates)\n",
        "\n",
        "  zero_mask = tf.scatter_nd(top_k_row_col_idxs, updates, [num_rows, 4])\n",
        "  # tf.print(\"\\n\",zero_mask)\n",
        "\n",
        "  scatter = twoDarr * zero_mask\n",
        "  # tf.print(\"\\n\",scatter)\n",
        "  return scatter"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rRRLY1s6hGiM",
        "colab_type": "code",
        "outputId": "e0b2a2be-abef-4d79-f3fe-0f7ea7974209",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "twoDarr = tf.random.uniform((3,4),minval=5,maxval=50,dtype=tf.dtypes.int32)\n",
        "k = 3\n",
        "\n",
        "tf.print(\"================= 2D Tensor of shape (?,n) before calculating top k values =================== \\n\")\n",
        "tf.print(twoDarr)\n",
        "\n",
        "output = task3(twoDarr,k)\n",
        "tf.print(\"\\n ================= 2D Tensor of shape (?,n) after calculating top k values and scatter =================== \\n\")\n",
        "tf.print(output)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "================= 2D Tensor of shape (?,n) before calculating top k values =================== \n",
            "\n",
            "[[19 18 10 47]\n",
            " [10 5 16 31]\n",
            " [24 37 40 15]]\n",
            "\n",
            " ================= 2D Tensor of shape (?,n) after calculating top k values and scatter =================== \n",
            "\n",
            "[[19 18 0 47]\n",
            " [10 0 16 31]\n",
            " [24 37 40 0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c4rsSmjzDf68",
        "colab_type": "text"
      },
      "source": [
        "# Task 4"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wbXcUDDrDlRB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@tf.function\n",
        "def task4(input,a):\n",
        "  arr = tf.TensorArray(dtype=tf.float32,size=0,dynamic_size=True,clear_after_read=False)\n",
        "  arr = arr.write(0,input[0])\n",
        "  for idx in range(1,input.shape[0]):\n",
        "    arr = arr.write(idx,(a * arr.read(idx-1) + (1-a) * input[idx]))\n",
        "    new = arr.stack()\n",
        "  return new"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yiOpnx6WDfLV",
        "colab_type": "code",
        "outputId": "5c90c24e-e02f-44db-c14e-7240f17a2fdf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "input = tf.range(1,6,dtype=tf.float32)\n",
        "a = tf.constant(0.20)    # decay rate\n",
        "tf.print(\"================= Input before calculating Exponentially moving Average =================== \\n\")\n",
        "tf.print(input)\n",
        "new = task4(input,a)\n",
        "tf.print(\"================= Output after calculating Exponentially moving Average =================== \\n\")\n",
        "tf.print(new)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "================= Input before calculating Exponentially moving Average =================== \n",
            "\n",
            "[1 2 3 4 5]\n",
            "================= Output after calculating Exponentially moving Average =================== \n",
            "\n",
            "[1 1.80000007 2.76000023 3.752 4.7504]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0AVASgHlDmzg",
        "colab_type": "text"
      },
      "source": [
        "# Task 5  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U9Szo8bjDoh6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# source - https://stackoverflow.com/questions/42869495/numpy-version-of-exponential-weighted-moving-average-equivalent-to-pandas-ewm handy0815\n",
        "def task5(input, a):\n",
        "\n",
        "    n = int(-100. / np.log(a)) # Makes sure that the first and last elements in f are very big and very small (about 1e22 and 1e-22)\n",
        "    f = np.exp(np.arange(1-n, n, 2) * (0.5 * np.log(a))) # Scaling factor for each slice\n",
        "    tmp = (np.resize(input, ((len(input) + n - 1) // n, n)) / f * (1. - a)).cumsum(axis=1) * f # Get ewm for each slice of length n\n",
        "\n",
        "    # Add the last value of each previous slice to the next slice with corresponding scaling factor f and return result\n",
        "    return np.resize(tmp + np.tensordot(np.append(input[0], np.roll(tmp.T[n-1], 1)[1:]), f * ((a) / f[0]), axes=0), len(input))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mr9P0oHHkY9L",
        "colab_type": "code",
        "outputId": "21d6e57b-ba00-4e70-806c-6f5dfdb24507",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "# input = tf.range(1,6,dtype=tf.float32)\n",
        "# a = tf.constant(0.20)    # decay rate\n",
        "\n",
        "input = [1.,2.,3.,4.,5.]\n",
        "a = 0.20\n",
        "tf.print(\"================= Input before calculating Exponentially moving Average =================== \\n\")\n",
        "tf.print(input)\n",
        "tf.print(\"================= Last Output after calculating Exponentially moving Average =================== \\n\")\n",
        "output = task5(input,a)\n",
        "tf.print(output[-1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "================= Input before calculating Exponentially moving Average =================== \n",
            "\n",
            "[1.0, 2.0, 3.0, 4.0, 5.0]\n",
            "================= Last Output after calculating Exponentially moving Average =================== \n",
            "\n",
            "4.750399999999998\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b0O1y7OJDvmx",
        "colab_type": "text"
      },
      "source": [
        "# Task 6"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nDudw_rSD0Dv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@tf.function\n",
        "def task6(x,y,z):\n",
        "  depth = x.shape\n",
        "  x = tf.unstack(tf.reshape(x, [-1]))\n",
        "  y = tf.unstack(tf.reshape(y, [-1]))\n",
        "  z = tf.unstack(tf.reshape(z, [-1]))\n",
        "  newarr = tf.TensorArray(dtype=tf.int32,size=0,dynamic_size=True,clear_after_read=False)\n",
        "  # print(x)\n",
        "  for i,m in enumerate(x):\n",
        "    if (m % 2 == 0):\n",
        "      newarr = newarr.write(i,y[i])  \n",
        "    else:\n",
        "       newarr = newarr.write(i,z[i]) \n",
        "  tf.print(\"================= Output after calculation =================== \\n\")\n",
        "  tf.print(tf.reshape(newarr.stack(),shape=depth))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CoRTBVGfEGhI",
        "colab_type": "code",
        "outputId": "e5318ce4-bb0f-48f9-80a6-ab468662541e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 680
        }
      },
      "source": [
        "x = tf.random.uniform((2,3,2),minval=0,maxval=100,dtype=tf.dtypes.int32)\n",
        "y = tf.random.uniform((2,3,2),minval=0,maxval=100,dtype=tf.dtypes.int32)\n",
        "z = tf.random.uniform((2,3,2),minval=0,maxval=100,dtype=tf.dtypes.int32)\n",
        "tf.print(\"================= Input x =================== \\n\")\n",
        "tf.print(x,\"\\n\")\n",
        "tf.print(\"================= Input y =================== \\n\")\n",
        "tf.print(y,\"\\n\")\n",
        "tf.print(\"================= Input z =================== \\n\")\n",
        "tf.print(z,\"\\n\")\n",
        "task6(x,y,z)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "================= Input x =================== \n",
            "\n",
            "[[[95 93]\n",
            "  [0 54]\n",
            "  [30 28]]\n",
            "\n",
            " [[53 22]\n",
            "  [92 97]\n",
            "  [41 85]]] \n",
            "\n",
            "================= Input y =================== \n",
            "\n",
            "[[[77 6]\n",
            "  [34 65]\n",
            "  [19 73]]\n",
            "\n",
            " [[81 44]\n",
            "  [39 44]\n",
            "  [45 53]]] \n",
            "\n",
            "================= Input z =================== \n",
            "\n",
            "[[[24 4]\n",
            "  [87 10]\n",
            "  [57 33]]\n",
            "\n",
            " [[93 54]\n",
            "  [46 75]\n",
            "  [14 22]]] \n",
            "\n",
            "================= Output after calculation =================== \n",
            "\n",
            "[[[24 4]\n",
            "  [34 65]\n",
            "  [19 73]]\n",
            "\n",
            " [[93 44]\n",
            "  [39 75]\n",
            "  [14 22]]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kBWJmKb5SuuL",
        "colab_type": "text"
      },
      "source": [
        "# Task 7"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LFIR_5ZdSxGy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@tf.function\n",
        "def task7(arr):\n",
        "  depth = arr.get_shape()\n",
        "  if depth[-1] > 100:\n",
        "    return 100\n",
        "  elif depth[-1] <= 100 and depth[-1] > 44:\n",
        "    return 12\n",
        "  else:\n",
        "    return 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N_Re-yhLUZ44",
        "colab_type": "code",
        "outputId": "dc89f77b-1e46-4ee3-b25b-8046c9c01434",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "x = tf.random.uniform(shape=(4,6,101),minval=100,maxval=150)\n",
        "result = task7(x)\n",
        "tf.print(\"=========== Result after checking size of last dimension =============== \\n\")\n",
        "tf.print(result)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "=========== Result after checking size of last dimension =============== \n",
            "\n",
            "100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QFquJg1dUZNv",
        "colab_type": "text"
      },
      "source": [
        "# Task 8 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LuSgZTZiYAIM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "i = tf.Variable(0,dtype=tf.int32)\n",
        "j = tf.Variable(0,dtype=tf.int32)\n",
        "k = tf.Variable(0,dtype=tf.int32)\n",
        "\n",
        "def first():\n",
        "  global i\n",
        "  i = i+1\n",
        " \n",
        "def second():\n",
        "  global j\n",
        "  j = j+1\n",
        "\n",
        "def third():\n",
        "  global k\n",
        "  k = k+1\n",
        "\n",
        "def task8(arr):\n",
        "  global i,j,k\n",
        "  depth = arr.get_shape()\n",
        "  if depth[-1] > 100:\n",
        "    first()\n",
        "    return 100\n",
        "  elif depth[-1] <= 100 and depth[-1] > 44:\n",
        "    second()\n",
        "    return 12\n",
        "  else:\n",
        "    third()\n",
        "    return 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jRdnZllMvU-A",
        "colab_type": "code",
        "outputId": "81511fde-0384-4dca-d7b7-7c70378896e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "x = tf.random.uniform(shape=(4,5,145),minval=100,maxval=150)\n",
        "for m in tf.range(10):\n",
        "   task8(x)\n",
        "tf.print(\"=========== Global variable update for i =============== \\n\")\n",
        "tf.print(i,j,k)\n",
        "\n",
        "x = tf.random.uniform(shape=(4,5,45),minval=100,maxval=150)\n",
        "for m in tf.range(15):\n",
        "   task8(x)\n",
        "tf.print(\"=========== Global variable update for j =============== \\n\")\n",
        "tf.print(i,j,k)\n",
        "\n",
        "x = tf.random.uniform(shape=(4,5,5),minval=100,maxval=150)\n",
        "for m in tf.range(20):\n",
        "   task8(x)\n",
        "tf.print(\"=========== Global variable update for k =============== \\n\")\n",
        "tf.print(i,j,k)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "=========== Global variable update for i =============== \n",
            "\n",
            "10 0 0\n",
            "=========== Global variable update for j =============== \n",
            "\n",
            "10 15 0\n",
            "=========== Global variable update for k =============== \n",
            "\n",
            "10 15 20\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zba6DIEZAawL",
        "colab_type": "text"
      },
      "source": [
        "When trying with tf.function , I am facing an error on tf.print(i,j,k) statement, \n",
        "\n",
        "Error : 'Tensor' object has no attribute '_datatype_enum'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fw3T_F0cYffC",
        "colab_type": "text"
      },
      "source": [
        "# Task 9"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wud7LP1QYhei",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@tf.function\n",
        "def task9(x,y):\n",
        "  result =  x[:,None]-y[None,:]   # [2,] - [,2] = [2,2]  element wise subtraction in x column elements are broadcasted and in y row elements are broadcasted\n",
        "  # result = tf.broadcast_to([x-y],[2,2]) # not working as desired  [[-3 0] [-3 0]]\n",
        "  # tf.print(result1,'\\n')\n",
        "  return result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lGAlzyoKYoeh",
        "colab_type": "code",
        "outputId": "fa991c89-12d4-4a2e-f5f3-92f42456e432",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "x = tf.random.uniform((2,),minval=0,maxval=5,dtype=tf.dtypes.int32)\n",
        "y = tf.random.uniform((2,),minval=0,maxval=10,dtype=tf.dtypes.int32)\n",
        "tf.print(\"================= Input Tensor of shape (n,) =================== \\n\")\n",
        "tf.print(x)\n",
        "tf.print(\"================= Input Tensor of shape (n,) =================== \\n\")\n",
        "tf.print(y)\n",
        "tf.print(\"================= Output Tensor of shape (n,n) =================== \\n\")\n",
        "output = task9(x,y)\n",
        "tf.print(output)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "================= Input Tensor of shape (n,) =================== \n",
            "\n",
            "[1 4]\n",
            "================= Input Tensor of shape (n,) =================== \n",
            "\n",
            "[4 1]\n",
            "================= Output Tensor of shape (n,n) =================== \n",
            "\n",
            "[[-3 0]\n",
            " [0 3]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O9X2X1E3mLwZ",
        "colab_type": "text"
      },
      "source": [
        "# Task 10"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Zs1MRVrmOcS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Source :  https://stackoverflow.com/questions/42507030/implementing-attention-in-tensorflow\n",
        "\n",
        "@tf.function\n",
        "def task10(batch_size,time,features):\n",
        "  # shape of sequence of encoder states h is batch x time x features 10 x 4 x 3\n",
        "  encoder_hidden_state = tf.constant(np.random.randn(batch_size, time, features), tf.float32)\n",
        "\n",
        "  # last decoder shape : batch x features  10 x 3\n",
        "  s = tf.constant(np.random.randn(batch_size, features), tf.float32)\n",
        "\n",
        "  W_HS = tf.random.uniform(shape = [features, features],minval=-0.03,maxval=0.03)\n",
        "  w_alpha = tf.random.uniform(shape = [features],minval=-0.03,maxval=0.03)\n",
        "\n",
        "  '''\n",
        "  Einsum allows defining Tensors by defining their element-wise computation.Steps to convert the element-wise equation into the equation:\n",
        "        1. remove variable names, brackets, and commas, (ik = sum_j ij * jk)\n",
        "        2. replace \"*\" with \",\", (ik = sum_j ij , jk)\n",
        "        3. drop summation signs, and (ik = ij, jk)\n",
        "        4. move the output to the right, while replacing \"=\" with \"->\". (ij,jk->ik)\n",
        "    '''\n",
        "  #  batch x time x features  -- tanh(W_HS^{encoder_hidden_state}encoder_hidden_state)\n",
        "  M = tf.tanh(tf.einsum(\"aij,jk->aik\", encoder_hidden_state, W_HS))\n",
        "\n",
        "  # print(M)\n",
        "  # batch_size x time        -- softmax(M w_alpha^T)\n",
        "  alpha = tf.nn.softmax(tf.einsum(\"aij,j->ai\", M, w_alpha))\n",
        "  return alpha"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HBQJh8WGIOph",
        "colab_type": "code",
        "outputId": "c9a450c0-0acf-4f24-e1a8-abcbbbe2486b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "batch_size = 6\n",
        "time = 4\n",
        "features = 3\n",
        "tf.print(\"\\n ================= Output attention matrix =================== \\n\")\n",
        "output = task10(batch_size,time,features)\n",
        "tf.print(output)\n",
        "tf.print(\"\\n ================= Output attention matrix shape (batch_size,time) =================== \\n\")\n",
        "tf.print(output.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "================= Output attention matrix =================== \n",
            "\n",
            "[[0.250110447 0.24997738 0.249937311 0.249974921]\n",
            " [0.250029653 0.249999806 0.250055641 0.249914855]\n",
            " [0.250080794 0.249877632 0.249849096 0.250192434]\n",
            " [0.249993011 0.250065446 0.250213832 0.249727711]\n",
            " [0.250130713 0.249761537 0.249999359 0.250108391]\n",
            " [0.250097036 0.249748081 0.25039348 0.249761388]]\n",
            "================= Output attention matrix shape (batch_size,time) =================== \n",
            "\n",
            "TensorShape([6, 4])\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}